# InvestorOS Chat

> ðŸ’¬ A local-first, streaming AI chat application built with React, Node.js, and Ollama.

---

## âœ¨ Features

- âš¡ **Streaming responses** via Server-Sent Events (SSE)  
- ðŸ§© **Modular architecture** (frontend + backend + model server)  
- ðŸŽ¨ **Modern UI** powered by React + MUI  
- ðŸ”Œ **Backend API** with Express and robust SSE handling  
- ðŸ¤– **LLM integration** with [Ollama](https://ollama.ai) (default: Mistral model)  
- ðŸ›‘ **Abortable requests** (cancel ongoing chat in real time)  
- ðŸ“œ **Chat history** with user + assistant roles  
- ðŸ“± **Responsive layout** (desktop/mobile friendly)

---

## ðŸ—ï¸ Architecture
React (frontend)
|
| fetch + SSE
v
Express (backend) ---> Ollama API (localhost:11434)


- **Frontend** (`ChatPage.jsx` + `streamChat.js`)  
  Handles user input, message rendering, and streaming tokens.  
- **Backend** (`chat.js`)  
  Provides `/api/chat` (sync) and `/api/chat/stream` (stream) endpoints.  
- **Ollama**  
  Local LLM runner, defaults to `mistral: latest`.

  ### 1. Prerequisites
- Node.js â‰¥ 18
- Yarn or npm
- [Ollama](https://ollama.ai) installed locally

### 2. Clone & Install
```bash
git clone https://github.com/your-username/investoros-chat.git
cd investoros-chat

# Install backend deps
cd server
npm install

# Install frontend deps
cd ../client
npm install
